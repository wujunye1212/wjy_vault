# è®ºæ–‡ç¬”è®°

## ä¸€ã€EEGç»¼è¿°ç±»

### 1.A review of Graph Neural Networks for Electroencephalography data analysisï¼ˆç”¨äºè„‘ç”µå›¾æ•°æ®åˆ†æçš„å›¾ç¥ç»ç½‘ç»œç»¼è¿°ï¼‰Neuro computing 2023

æœ¬æ–‡ç« è¿›è¡Œäº†æ±‡æ€»ï¼Œå¯ä»¥ä½œä¸ºå¼•å­ï¼Œæœ‰å‡ ä¸ªæ–¹å‘çš„ä»‹ç»ï¼Œæ¯”å¦‚ï¼šç™«ç—«ã€æƒ…ç»ªã€è„‘æœºæ¥å£ã€ç²¾ç¥ç–¾ç—…ã€‚

å¯¹äºç²¾ç¥ç–¾ç—…æ¥è¯´ï¼šå¼•ç”¨æ–‡çŒ®ã€ŠClassification of first-episode schizophrenia, chronic schizophrenia and healthy control based on brain network of mismatch negativity by graph neural networkã€‹å±•ç¤ºäº†

![image-20251117203610318](assets/å­¦æœ¯ç¬”è®°/image-20251117203610318.png)

 "CNN çš„æˆåŠŸå¯å½’å› äºå…¶åˆ†å±‚ç»“æ„, è¿™ä½¿å®ƒä»¬èƒ½å¤Ÿä»æ¬§å‡ é‡Œå¾—åŸŸçš„æ•°æ®ä¸­æå–å’Œæ•´åˆå¤šå°ºåº¦ç‰¹ å¾ã€‚éæ¬§å‡ é‡Œå¾—åŸŸ(ä¾‹å¦‚ç¤¾äº¤ç½‘ç»œã€åŸºå› æ•°æ®å’Œè„‘ç½‘ç»œ) ä¸­çš„æ•°æ®å¯ä»¥é€šè¿‡å›¾è¿›è¡Œç¼–ç ,è¿™äº›å›¾ä¸ä»…åŒ…å«é‡åŒ–å…ƒç´ , è¿˜åŒ…å«å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚"

## äºŒã€EEGæ— ä»£ç è®ºæ–‡

### 1.EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Modelï¼ˆEEGFormer:è¿ˆå‘å¯è¿ç§»ä¸”å¯è§£é‡Šçš„å¤§è§„æ¨¡è„‘ç”µå›¾åŸºç¡€æ¨¡å‹ï¼‰

![image-20251118101252869](assets/å­¦æœ¯ç¬”è®°/image-20251118101252869.png)

å¯¹å¤§é‡eegè¿›è¡Œé¢„è®­ç»ƒï¼Œå¯¹æ¯ä¸ªé¢‘æ®µç¼–ç 



## å›¾å·ç§¯çŸ¥è¯†

### 1. æ ‡å‡†å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰å±‚ï¼ˆKipf & Welling 2017ï¼‰ç®€åŒ–å·ç§¯

GCN å±‚é€šè¿‡å¯¹é‚»æ¥çŸ©é˜µçš„å½’ä¸€åŒ–ï¼Œå°†æ¶ˆæ¯èšåˆå’Œç‰¹å¾è½¬æ¢åˆå¹¶åœ¨ä¸€ä¸ªçº¿æ€§æ“ä½œä¸­ã€‚GCN å±‚çš„ç‰¹å¾ä¼ æ’­å…¬å¼ï¼š$\mathbf{H}^{(l+1)} = \sigma \left( \tilde{\mathbf{D}}^{-\frac{1}{2}} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} \mathbf{H}^{(l)} \mathbf{W}^{(l)} \right)$ï¼Œå…¶ä¸­**$H^{(l)} \in \mathbb{R}^{N \times F_{in}}$**ï¼šç¬¬ $l$ å±‚çš„èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µã€‚$N$ æ˜¯èŠ‚ç‚¹æ•°ï¼Œ$F_{in}$ æ˜¯è¾“å…¥ç‰¹å¾ç»´åº¦ï¼Œ**$W^{(l)} \in \mathbb{R}^{F_{in} \times F_{out}}$**ï¼šç¬¬ $l$ å±‚å¯å­¦ä¹ çš„æƒé‡çŸ©é˜µï¼ˆçº¿æ€§å˜æ¢ï¼‰ï¼Œ**$\tilde{A} = A + I_N$**ï¼šæ·»åŠ äº†è‡ªç¯ï¼ˆSelf-loopsï¼‰çš„é‚»æ¥çŸ©é˜µã€‚ä¸ºä»€ä¹ˆè¦åŠ  $I_N$ï¼Ÿå¦‚æœä¸åŠ è‡ªç¯ï¼ŒèŠ‚ç‚¹åœ¨æ›´æ–°æ—¶åªèšåˆé‚»å±…çš„ä¿¡æ¯ï¼Œè€Œå¿½ç•¥äº†è‡ªèº«çš„ç‰¹å¾ã€‚$\tilde{A}$ ç¡®ä¿äº†è‡ªèº«ç‰¹å¾ä¹Ÿå‚ä¸ä¸‹ä¸€æ¬¡è¿­ä»£ï¼Œ**$\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$**ï¼š$\tilde{A}$ çš„åº¦çŸ©é˜µï¼ˆDegree Matrixï¼‰ï¼Œæ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼Œ**$\sigma(\cdot)$**ï¼šéçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸ä½¿ç”¨ $\text{ReLU}$ã€‚

å‰å‘ä¼ æ’­ï¼š

**ç¬¬ä¸€æ­¥**ï¼šç‰¹å¾å˜æ¢ é¦–å…ˆå¯¹èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œçº¿æ€§æŠ•å½±ï¼š$Z^{(l)} = H^{(l)} W^{(l)}$ç»´åº¦å˜æ¢$(N \times F_{in}) \times (F_{in} \times F_{out}) \rightarrow (N \times F_{out})$ï¼Œç‰©ç†æ„ä¹‰ï¼šè¿™ä¸€æ­¥ç±»ä¼¼äºä¼ ç»Ÿ CNN ä¸­çš„ $1 \times 1$ å·ç§¯æˆ– MLPï¼Œæ—¨åœ¨å°†ç‰¹å¾æ˜ å°„åˆ°æ–°çš„é«˜ç»´æˆ–ä½ç»´ç©ºé—´ï¼Œä»¥æå–æ›´é«˜é˜¶çš„è¯­ä¹‰ç‰¹å¾ã€‚ 

**ç¬¬äºŒæ­¥**ï¼šå›¾ç»“æ„å½’ä¸€åŒ–ä¸æ¶ˆæ¯èšåˆè¿™æ˜¯GCNçš„çµé­‚æ‰€åœ¨ã€‚æˆ‘ä»¬å°†å˜æ¢åçš„ç‰¹å¾ $Z^{(l)}$ å·¦ä¹˜å½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µï¼š$$\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$$ï¼Œ$$H_{agg} = \hat{A} Z^{(l)}$$å¯¹ç§°å½’ä¸€åŒ–ï¼š$\hat{A}_{ij} = \frac{\tilde{A}_{ij}}{\sqrt{\tilde{d}_i \tilde{d}_j}}$ã€‚ç›¸æ¯”äºéšæœºæ¸¸èµ°å½’ä¸€åŒ–ï¼ˆ$D^{-1}A$ï¼‰ï¼Œå¯¹ç§°å½’ä¸€åŒ–ä¿æŒäº†çŸ©é˜µçš„å¯¹ç§°æ€§ï¼Œè¿™å¯¹è°±åˆ†æè‡³å…³é‡è¦ã€‚ç‰©ç†æ„ä¹‰ï¼šå®ƒåœ¨èšåˆé‚»å±…ä¿¡æ¯æ—¶ï¼Œä¸ä»…è€ƒè™‘äº†èŠ‚ç‚¹ $i$ è‡ªèº«çš„åº¦ï¼ˆåº¦å¤§åˆ™æƒé‡ä½ï¼Œé¿å…hubèŠ‚ç‚¹è¿‡åº¦æ”¯é…ï¼‰ï¼Œä¹Ÿè€ƒè™‘äº†é‚»å±… $j$ çš„åº¦ï¼ˆé‚»å±…åº¦å¤§ï¼Œè¯´æ˜è¯¥é‚»å±…çš„å½±å“åŠ›è¢«åˆ†æ•£äº†ï¼Œä¼ ç»™ $i$ çš„æƒé‡ä¹Ÿåº”é™ä½ï¼‰ã€‚æ¶ˆæ¯ä¼ é€’ï¼šè¿™ä¸€æ­¥å®ç°äº†å±€éƒ¨å¹³æ»‘ï¼Œæ¯ä¸ªèŠ‚ç‚¹ $i$ æ”¶é›†å…¶ä¸€é˜¶é‚»å±…ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰çš„åŠ æƒç‰¹å¾å’Œã€‚

ç¬¬ä¸€æ­¥ï¼šå›¾å·ç§¯çš„åŸå§‹å®šä¹‰ï¼ˆè°±åŸŸè§†è§’ï¼‰

â€‹	åœ¨å›¾åƒä¸­ï¼Œå·ç§¯æ˜¯åˆ©ç”¨å›ºå®šå¤§å°çš„æ ¸åœ¨ç½‘æ ¼ä¸Šæ»‘åŠ¨ã€‚ä½†åœ¨å›¾ä¸Šï¼ŒèŠ‚ç‚¹æ’åˆ—æ— åºï¼Œæ— æ³•ç›´æ¥â€œæ»‘åŠ¨â€ã€‚ äºæ˜¯æ•°å­¦å®¶åˆ©ç”¨**å·ç§¯å®šç†**ï¼š$$f * g = \mathcal{F}^{-1} \big( \mathcal{F}(f) \cdot \mathcal{F}(g) \big)$$å³ï¼šæ—¶åŸŸï¼ˆç©ºåŸŸï¼‰çš„å·ç§¯ç­‰äºé¢‘åŸŸçš„ä¹˜ç§¯ã€‚è¦åœ¨å›¾ä¸Šåšå·ç§¯ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å›¾çš„â€œå‚…é‡Œå¶å˜æ¢â€ã€‚åŸºåº•ï¼šå›¾çš„æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ $L = D - A$ çš„ç‰¹å¾å‘é‡çŸ©é˜µ $U$ å°±æ˜¯å›¾çš„å‚…é‡Œå¶åŸºã€‚å˜æ¢ï¼šå›¾ä¿¡å· $x$ çš„å‚…é‡Œå¶å˜æ¢æ˜¯ $\hat{x} = U^T x$ã€‚é‚£ä¹ˆï¼Œ**å›¾å·ç§¯æœ€åˆè¢«å®šä¹‰ä¸º**ï¼š$$g_{\theta} \star x = U g_{\theta}(\Lambda) U^T x$$ï¼Œå…¶ä¸­ï¼š$x$ æ˜¯è¾“å…¥ä¿¡å·ï¼ˆèŠ‚ç‚¹ç‰¹å¾ï¼‰ã€‚$U$ æ˜¯æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹å¾å‘é‡ã€‚$g_{\theta}(\Lambda)$ æ˜¯å·ç§¯æ ¸ï¼ˆæ»¤æ³¢å™¨ï¼‰ï¼Œæ˜¯æˆ‘ä»¬éœ€è¦å­¦ä¹ çš„å¯¹è§’çŸ©é˜µå‚æ•°ã€‚**ç—›ç‚¹**ï¼šè®¡ç®—ç‰¹å¾å‘é‡çŸ©é˜µ $U$ éœ€è¦å¯¹ $L$ è¿›è¡Œç‰¹å¾åˆ†è§£ï¼Œå¤æ‚åº¦æ˜¯ $O(N^3)$ã€‚å¯¹äºå¤§å›¾ï¼Œè¿™æ ¹æœ¬ä¸å¯è¡Œã€‚

ç¬¬äºŒæ­¥ï¼šåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼è¿‘ä¼¼

â€‹	ä¸ºäº†é¿å…è®¡ç®— $U$ï¼Œå­¦è€…ä»¬å¼•å…¥äº†**åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼**æ¥è¿‘ä¼¼é‚£ä¸ªå·ç§¯æ ¸ $g_{\theta}(\Lambda)$ã€‚åŸç†æ˜¯ï¼šä»»ä½•å‡½æ•°éƒ½å¯ä»¥ç”¨å¤šé¡¹å¼çº§æ•°é€¼è¿‘ã€‚æ­¤æ—¶å·ç§¯å˜æˆäº†ï¼š$$g_{\theta'} \star x \approx \sum_{k=0}^K \theta'_k T_k(\tilde{L}) x$$â€‹ï¼Œ$T_k$ æ˜¯ $k$ é˜¶åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼ï¼Œ$\tilde{L}$ æ˜¯å½’ä¸€åŒ–åçš„æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µã€‚**K**ï¼šä»£è¡¨å·ç§¯æ ¸çš„å¤§å°ï¼Œä¹Ÿå°±æ˜¯æ„Ÿå—é‡ã€‚$K=1$ ä»£è¡¨åªçœ‹ä¸€é˜¶é‚»å±…ï¼Œ$K=2$ ä»£è¡¨çœ‹äºŒé˜¶é‚»å±…ã€‚**å¥½å¤„**ï¼šä¸å†éœ€è¦ç‰¹å¾åˆ†è§£ï¼Œåªéœ€è¦ç®—çŸ©é˜µçš„å¹‚ $L^k$ï¼Œè¿™å°±å˜æˆäº†å±€éƒ¨æ“ä½œï¼Œè®¡ç®—é‡å¤§å¤§é™ä½ã€‚

ç¬¬ä¸‰æ­¥ï¼šKipf & Welling çš„â€œä¸€é˜¶è¿‘ä¼¼â€ (GCN 2017)

â€‹	Kipf åšäº†ä¸€ä¸ªéå¸¸å¤§èƒ†çš„ç®€åŒ–ï¼ŒæŠŠä¸Šé¢çš„åˆ‡æ¯”é›ªå¤«è¿‘ä¼¼æ¨åˆ°äº†æè‡´ã€‚1. é™åˆ¶ K=1ï¼ˆä¸€é˜¶è¿‘ä¼¼ï¼‰Kipf è®¤ä¸ºï¼Œæˆ‘ä»¬ä¸éœ€è¦åœ¨å•å±‚é‡Œçœ‹å¾—å¾ˆè¿œï¼Œåªçœ‹ä¸€é˜¶é‚»å±…ï¼ˆ$K=1$ï¼‰å°±å¤Ÿäº†ï¼Œé€šè¿‡å †å å¤šå±‚ç½‘ç»œæ¥æ‰©å¤§æ„Ÿå—é‡ã€‚å½“ $K=1$ æ—¶ï¼Œå…¬å¼ç®€åŒ–ä¸ºå…³äº $\tilde{L}$ çš„çº¿æ€§å‡½æ•°ï¼š$$g_{\theta'} \star x \approx \theta'_0 x + \theta'_1 \tilde{L} x$$ï¼Œå‚æ•°å…±äº«ä¸çº¦æŸç°åœ¨çš„å…¬å¼é‡Œæœ‰ä¸¤ä¸ªå‚æ•° $\theta'_0$ å’Œ $\theta'_1$ã€‚ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆå’Œå‡å°‘è®¡ç®—é‡ï¼ŒKipf å¼ºåˆ¶ä»¤ $\theta'_0 = - \theta'_1 = \theta$ã€‚ç»“åˆæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„å®šä¹‰ï¼ˆ$\tilde{L} = I - \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ï¼‰ï¼Œæ¨å¯¼è¿‡ç¨‹å¦‚ä¸‹ï¼š$$\begin{aligned} g \star x &\approx \theta(I) x - \theta(\tilde{L}) x \\ &= \theta(I - \tilde{L}) x \\ &= \theta \left( I - (I - \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}) \right) x \\ &= \theta \left( \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}} \right) x \end{aligned}$$

çœ‹ï¼è¿™å°±å‡ºç°äº† $\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ è¿™ä¸ªæ ¸å¿ƒç»“æ„ã€‚Renormalization Trick (é‡å½’ä¸€åŒ–æŠ€å·§)ä¸Šé¢æ¨å¯¼å‡ºçš„ $\tilde{A}$ æ˜¯åŸå§‹é‚»æ¥çŸ©é˜µï¼Œå¯¹è§’çº¿ä¸º0ã€‚å¦‚æœä¸å¤„ç†ï¼Œç›´æ¥ä¹˜è¿™ä¸ªçŸ©é˜µï¼Œç»è¿‡æ·±å±‚ç½‘ç»œåï¼Œç‰¹å¾å€¼çš„èŒƒå›´ä¼šä½¿å¾—æ•°å€¼ä¸ç¨³å®šï¼ˆæ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±ï¼‰ã€‚äºæ˜¯ï¼ŒKipf æå‡ºäº† Renormalization Trickï¼šç›´æ¥ç”¨ $\tilde{A} = A + I$ ï¼ˆåŠ äº†è‡ªç¯çš„é‚»æ¥çŸ©é˜µï¼‰æ¥ä»£æ›¿ä¸Šé¢çš„ç»“æ„ã€‚æœ€ç»ˆå…¬å¼å°±è¯ç”Ÿäº†ï¼š$$Z = \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}} X W$$

# å°æŠ€å·§éšè®°

### 1.å¯¹äºaiçš„å…¬å¼æ¸²æŸ“å¤±è´¥

ç­”ï¼šä½¿ç”¨è¿™ä¸ªæç¤ºè¯ ï¼Œå°±å¯ä»¥æ­£å¸¸æ¸²æŸ“æ•°å­¦å…¬å¼äº†

è¯·ä½ ä»¥æ ‡å‡† LaTeX æ ¼å¼è¾“å‡ºæ•°å­¦å…¬å¼ï¼Œå…·ä½“è¦æ±‚å¦‚ä¸‹ï¼š

1. ä½¿ç”¨æ ‡å‡† LaTeX è¯­æ³•ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•éæ ‡å‡†æ ‡è®°ï¼ˆå¦‚ æ ‡ç­¾ï¼‰ã€‚

2. å¦‚æœæ˜¯è¡Œå†…å…¬å¼ï¼Œè¯·ç”¨å•ä¸ªç¾å…ƒç¬¦å· $ åŒ…è£¹å…¬å¼ã€‚

3. å¦‚æœæ˜¯ç‹¬ç«‹å…¬å¼å—ï¼Œè¯·ç”¨åŒç¾å…ƒç¬¦å· $$ åŒ…è£¹å…¬å¼ï¼Œå¹¶å°†å…¬å¼å±…ä¸­æ˜¾ç¤ºã€‚

4. ç¡®ä¿å…¬å¼ä¸­çš„ç¬¦å·ã€è¿ç®—ç¬¦ã€ä¸Šä¸‹æ ‡å’Œæ‹¬å·ç­‰ç¬¦åˆ LaTeX è¯­æ³•è§„èŒƒã€‚

5. å…¬å¼åº”æ¸…æ™°ã€ç®€æ´ï¼Œå°½é‡é¿å…ä½¿ç”¨æ¨¡ç³Šæˆ–ä¸æ˜ç¡®çš„ç¬¦å·ã€‚

6. æ ¹æ®å…¬å¼çš„å¤æ‚åº¦ï¼Œå†³å®šä½¿ç”¨è¡Œå†…å…¬å¼è¿˜æ˜¯ç‹¬ç«‹å…¬å¼å—ã€‚

7. å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä¸ºå…¬å¼æ·»åŠ ç®€çŸ­çš„æ³¨é‡Šæˆ–è¯´æ˜ã€‚

   

### 2.æ¨¡å—ç¼åˆé—®é¢˜

å¯¹äºè¿™ä¸ªé—®é¢˜

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from functorch.einops import rearrange
from DilateFormer import MultiDilatelocalAttention
from HWDå°æ³¢ä¸‹é‡‡æ · import Down_wt
from LSK import LSKblock
from MobileViTv2Attention import MobileViTv2Attention
from ScConvå·ç§¯ import ScConv
from éƒ¨åˆ†å·ç§¯ import Partial_conv3
class DoubleConv(nn.Sequential):
    def __init__(self, in_channels, out_channels, mid_channels=None):
        if mid_channels is None:
            mid_channels = out_channels
        super(DoubleConv, self).__init__(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            ScConv(mid_channels),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            Partial_conv3(out_channels, 2, 'split_cat'),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
class Down(nn.Sequential):
    def __init__(self, in_channels, out_channels):
        super(Down, self).__init__(
            #nn.MaxPool2d(2, stride=2),
            Down_wt(in_channels, in_channels),
            DoubleConv(in_channels, out_channels)
        )
class Up(nn.Module):
    def __init__(self, in_channels, out_channels, bilinear=True):
        super(Up, self).__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # [N, C, H, W]
        diff_y = x2.size()[2] - x1.size()[2]
        diff_x = x2.size()[3] - x1.size()[3]
        # padding_left, padding_right, padding_top, padding_bottom
        x1 = F.pad(x1, [diff_x // 2, diff_x - diff_x // 2,
                        diff_y // 2, diff_y - diff_y // 2])

        x = torch.cat([x2, x1], dim=1)
        x = self.conv(x)
        return x
class OutConv(nn.Sequential):
    def __init__(self, in_channels, num_classes):
        super(OutConv, self).__init__(
            nn.Conv2d(in_channels, num_classes, kernel_size=1)
        )
def to_3d(x):
    return rearrange(x, 'b c h w -> b (h w) c')
def to_4d(x, h, w):
    return rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)
class UNet(nn.Module):
    def __init__(self,
                 in_channels: int = 1,
                 num_classes: int = 2,
                 bilinear: bool = True,
                 base_c: int = 64):
        super(UNet, self).__init__()
        self.in_channels = in_channels
        self.num_classes = num_classes
        self.bilinear = bilinear
        self.in_conv = DoubleConv(in_channels, base_c)
        self.down1 = Down(base_c, base_c * 2)
        self.lsk=LSKblock(base_c * 2)
        self.down2 = Down(base_c * 2, base_c * 4)
        self.md=MultiDilatelocalAttention(base_c * 4)
        self.mv=MobileViTv2Attention(base_c * 4)
        self.down3 = Down(base_c * 4, base_c * 8)
        factor = 2 if bilinear else 1
        self.down4 = Down(base_c * 8, base_c * 16 // factor)
        self.up1 = Up(base_c * 16, base_c * 8 // factor, bilinear)
        self.up2 = Up(base_c * 8, base_c * 4 // factor, bilinear)
        self.up3 = Up(base_c * 4, base_c * 2 // factor, bilinear)
        self.up4 = Up(base_c * 2, base_c, bilinear)
        self.out_conv = OutConv(base_c, num_classes)
    def forward(self, x):
        x1 = self.in_conv(x)
        x2 = self.down1(x1)
        x2 = self.lsk(x2)
        x3 = self.down2(x2)
        print("x3",x3.shape)
        x3 = to_3d(x3)
        print("x3",x3.shape)
        x3 = self.mv(x3)
        x3 = to_4d(x3,16,16)#è¿™é‡ŒğŸ”to_3dè¦åŠ å…¥ä¸¤ä¸ªå‚æ•°  to_4d(x3,16,16)åé¢ä¸¤ä¸ª16æ˜¯åŸå§‹æ•°æ®çš„hå’Œw
        # x = x.permute(0, 2, 3, 1)  # ã€B, C, H, Wã€‘ -> ã€B, H, W, Cã€‘ğŸ”è¿™ä¸ªåœ°æ–¹å°ºå¯¸é—®é¢˜ å¾ˆé‡è¦
        # x= x.permute(0, 3, 1, 2)  # ã€B, H, W, Cã€‘ -> ã€B, C, H, Wã€‘
        x3 = x3.permute(0, 2, 3, 1)
        x3 = self.md(x3)
        x3 = x3.permute(0, 3, 1, 2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.out_conv(x)
        return x
# è¾“å…¥ B C H W,  è¾“å‡º B C H W
if __name__ == '__main__':
    block = UNet()
    input = torch.rand(3, 1, 64, 64)
    output = block(input)
    print(input.size(), output.size())

```

è®°å¾—print("ç¬¦å·ï¼š",x.shape)ï¼Œæ¥ä¸‹æ¥å°±æ˜¯bhwcè¿™ç§å°ºå¯¸é—®é¢˜ï¼šbatchï¼š0ï¼ˆæœ‰çš„æ—¶å€™æ˜¯Nï¼‰ï¼Œchannelï¼š1ï¼Œheightï¼š2ï¼Œwidthï¼š3   ğŸ‘‰(B/N,C,H,W)

### 3.è¯»æ–‡çŒ®

æ–¹æ³•è®ºï¼š

æœ¬è´¨ï¼šçœ‹è®ºæ–‡æœ¬èº«ä¸æ˜¯ç›®çš„ï¼Œè€Œæ˜¯**æ‰‹æ®µ**ï¼Œä¸»è¦çœ‹ä»–æ€ä¹ˆè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç”¨ä»€ä¹ˆæ€è·¯å’Œè§’åº¦  

Why-ä¸ºä»€ä¹ˆè¦åšè¿™ä¸ªç ”ç©¶ï¼Ÿå…³æ³¨ç‚¹ï¼š **Introduction** ä¸­ä¼šé˜è¿°**æœ¬é¡¹ç ”ç©¶çš„é‡å¤§æ„ä¹‰**ã€è¦è§£å†³ä»€ä¹ˆå·¥ç¨‹éš¾é¢˜æˆ–æ­ç¤ºä»€ä¹ˆç‰©ç†æœºåˆ¶ï¼Ÿè§£å†³é—®é¢˜çš„ç´§è¿«æ€§ç­‰å†…å®¹ã€‚

What-ç ”ç©¶å‘ç°äº†ä»€ä¹ˆï¼Œ**å¾—å‡ºäº†ä»€ä¹ˆç»“è®ºï¼Ÿ**å…³æ³¨ç‚¹ï¼š **æ‘˜è¦ä¸­ä¼šç›´æ¥ä½“ç°æœ€æ ¸å¿ƒçš„ç»“è®º**ï¼Œå¯¹äºæŸé—®é¢˜æœ‰ä»€ä¹ˆæ–°çš„è®¤è¯†ï¼Ÿæå‡ºäº†ä»€ä¹ˆæ–°çš„ç ”ç©¶æ–¹æ³•ï¼Ÿå¾—åˆ°äº†ä»€ä¹ˆæ–°çš„ç ”ç©¶ç»“è®ºï¼Ÿå…ˆçœ‹æ‘˜è¦ï¼Œç”±äºæ‘˜è¦ç¯‡å¹…å—é™ï¼Œæ›´å…·ä½“çš„ç»“è®ºå¯åˆ° Conclusion æˆ– discussion ä¸­æŸ¥çœ‹ã€‚

How-ç ”ç©¶æ˜¯å¦‚ä½•å®æ–½çš„ï¼Œç”¨äº†ä»€ä¹ˆæ–¹æ³•/æŠ€æœ¯ï¼Ÿå…³æ³¨ç‚¹ï¼šè¿™éƒ¨åˆ†å±äºè¾ƒä¸ºå…·ä½“ã€ç»†è‡´çš„å†…å®¹ï¼Œç ”ç©¶çš„å®æ–½è¿‡ç¨‹å°±æ˜¯è®ºæ–‡çš„ä¸»ä½“å†…å®¹ã€‚å¯¹äºè¯•éªŒç±»è®ºæ–‡ï¼ŒåŒ…æ‹¬è¯•éªŒç›®çš„ä¸æ€è·¯ã€è¯•éªŒè®¾å¤‡ä¸ææ–™å‡†å¤‡ã€è¯•éªŒæ–¹æ³•ä¸æ­¥éª¤ã€è¯•éªŒç°è±¡ã€è¯•éªŒç»“æœã€è¯•éªŒæœºç†æ­ç¤ºç­‰ã€‚å¯¹äº**æ•°å€¼è®¡ç®—ç±»**è®ºæ–‡ï¼ŒåŒ…æ‹¬å·¥ç¨‹èƒŒæ™¯ä»‹ç»ã€æ•°å€¼æ¨¡å‹ï¼ˆæœ¬æ„ã€å‚æ•°ã€æ ‡å®šæ–¹æ³•ï¼‰ã€è¯•éªŒ/å®æµ‹/ç†è®ºéªŒè¯ã€æ•°å€¼è®¡ç®—å·¥å†µã€è®¡ç®—ç»“æœåˆ†æã€å·¥ç¨‹é—®é¢˜æœºç†æ­ç¤ºç­‰ã€‚å¯¹äº**ç†è®ºæ¨å¯¼ç±»è®ºæ–‡**ï¼ŒåŒ…æ‹¬ç†è®ºç®€ä»‹ã€ç†è®ºæ¨å¯¼ã€è¯•éªŒ/å®æµ‹/æ•°å€¼æ¨¡æ‹ŸéªŒè¯ã€ç®—ä¾‹åˆ†æã€å‚æ•°åˆ†æç­‰ã€‚

é€šè¿‡è¿™ä¸‰ä¸ªé—®é¢˜ï¼Œæ¨å‡ºæœ€ç»ˆç›®çš„ç§‘ç ” Ideasï¼Œå³è¿™ç¯‡æ–‡çŒ®æœ‰å“ªäº›ä¸è¶³ï¼Ÿ ä½ å¯ä»¥åœ¨å“ªäº›æ–¹é¢è¿›è¡Œåˆ›æ–°ï¼Ÿ å¯è¡¨ç¤ºä¸ºWWHâ†’Ideasã€‚

### 4.åˆ›æ–°ç‚¹

æ–¹æ³•è®ºï¼š

æ‰¾åˆ›æ–°ç‚¹ä¸»è¦åœ¨äºæ–‡çŒ®é¡¶åˆŠï¼Œå‘ç°æ–‡ç« ç¼ºé™·ï¼Œåœ¨ä»€ä¹ˆåœ°æ–¹è¿˜æœ‰å¯ä»¥æ”¹è¿›çš„æ–¹å‘ã€‚**æ–‡çŒ®çš„ä¸è¶³ä¹‹å¤„ä¸»è¦æœ‰**ï¼šå¯¹äº XX é—®é¢˜å°‘æœ‰ç ”ç©¶ï¼›é’ˆå¯¹ XX é—®é¢˜æˆ–å·¥å†µï¼Œç¼ºä¹æœ‰æ•ˆå¯è¡Œçš„åˆ†æè¯„ä»·æ–¹æ³•ï¼›ä»…é˜è¿°è¯•éªŒç°è±¡ï¼Œæœªæ­ç¤ºç°è±¡èƒŒåçš„ç‰©ç†æœºåˆ¶ï¼Œæœªæ€»ç»“å‡ºæœ‰æ•ˆçš„é¢„æµ‹æ–¹æ³•ï¼›ç¼ºä¹å®æµ‹éªŒè¯ï¼›ç†è®ºå‡è®¾ä¸åˆç†ï¼›ç†è®ºæ¨å¯¼ä¸ä¸¥å¯†ï¼›æ•°å€¼è®¡ç®—å‚æ•°è¿‡å¤šä¸”éš¾ä»¥æ ‡å®šï¼›è®¡ç®—æ•ˆç‡è¿‡ä½ï¼›è®¡ç®—è¯¯å·®è¾ƒå¤§ï¼›è¯•éªŒç»“æœä¸è¶³ä»¥æ”¯æ’‘å¾—å‡ºç°æœ‰ç»“è®ºç­‰ã€‚  

ç§‘ç ”åˆ›æ–°æ€§æ’åºï¼šæ–°é—®é¢˜æ–°æ–¹æ³•ï¼ˆtopæœŸåˆŠæˆæœï¼‰>è€é—®é¢˜æ–°æ–¹æ³•ï¼ˆtopã€ä¸»æµæœŸåˆŠæˆæœï¼‰>æ–°é—®é¢˜è€æ–¹æ³•ï¼ˆä¸»æµæœŸåˆŠæˆæœï¼‰>è€é—®é¢˜è€æ–¹æ³•ï¼ˆåƒåœ¾æœŸåˆŠæˆæœç”šè‡³éš¾ä»¥å‘è¡¨ï¼‰

ç§‘ç ”åˆ›æ–°ç‚¹ä¸»è¦æœ‰ï¼šé’ˆå¯¹ XX æ–°é—®é¢˜æˆ–ç‰¹æ®Šå·¥å†µï¼Œæå‡ºæ–°çš„æˆ–æ”¹è¿›çš„è¯„ä»·æ–¹æ³•ï¼›å‘ç°æ–°ç°è±¡ï¼Œæ­ç¤ºæ–°æœºåˆ¶ï¼›é€šè¿‡è¯•éªŒç°è±¡æ€»ç»“è§„å¾‹ï¼Œå¹¶å½¢æˆè¯„ä»·æ–¹æ³•æˆ–å…¬å¼ï¼Œå¯ç”¨äºè§£å†³å®é™…å·¥ç¨‹é—®é¢˜ï¼›å¼€å‘æ–°ç®—æ³•ï¼Œå¯æ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ï¼›å¼€å±•æ–°å·¥å†µä¸‹çš„è¯•éªŒï¼Œç ”ç©¶æ–°é—®é¢˜ã€‚ 

**ç›®å‰åªæŒæ¡æ¨¡å—ç¼åˆ** ï¼›ä½†æ˜¯æ¨¡å—ç¼åˆæœ‰ç®€å•ä¸²å¹¶è”ã€å†…åµŒ

### 5.çœ‹æ–‡çŒ®æ­¥éª¤æ€»ç»“ï¼š

è§£å†³çš„é—®é¢˜ï¼ˆç—›ç‚¹ï¼‰â†’è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ï¼ˆè¿™ä¸ªæ–¹æ³•åŒ…æ‹¬å»ºç«‹åœ¨è°çš„åŸºç¡€ä¸Šï¼Œè§£å†³äº†å‰äººé—®é¢˜çš„ä»€ä¹ˆç—›ç‚¹ï¼‰â†’æ€è€ƒåˆ›æ–°ç‚¹ï¼ˆåˆ›æ–°ç‚¹æ˜¯åœ¨è¿™ä¸ªå‰äººåŸºç¡€çš„å¦ä¸€ä¸ªè§’åº¦çš„ç—›ç‚¹ï¼Œæˆ–è€…æ˜¯å½“å‰å®éªŒçš„ä¸è¶³çš„ç‚¹ï¼‰

### 6.æ‰“å°æ¨¡å‹ç»†èŠ‚

å®ä¾‹åŒ–æ¨¡å‹

```python
if __name__=='__main__':
	vit = VisionTransformer()
	print(vit)
```

### 7.pythonåŸºç¡€

__æ˜¯å¼ºåˆ¶ç§æœ‰       _å°±æ˜¯æ˜ç¡®ç§æœ‰å¤–éƒ¨ä¹Ÿå¯ä»¥è°ƒç”¨

```python
# å®šä¹‰ä¸€ä¸ªç±»ï¼ˆè“å›¾ï¼‰
class Dog:
    # __init__ æ˜¯æ„é€ å‡½æ•°ï¼Œåœ¨å®ä¾‹åŒ–æ—¶è‡ªåŠ¨è°ƒç”¨
    # self ä»£è¡¨å®ä¾‹æœ¬èº«
    def __init__(self, name, breed):
        # ç»™å®ä¾‹æ·»åŠ å±æ€§
        self.name = name
        self.breed = breed

    # ç»™å®ä¾‹æ·»åŠ æ–¹æ³•
    def bark(self):
        print(f"{self.name} æ±ªæ±ªå«ï¼")

# --- å®ä¾‹åŒ–è¿‡ç¨‹ ---
# æ ¹æ® Dog ç±»ï¼Œåˆ›å»ºä¸€ä¸ªåä¸º "æ—ºè´¢" çš„å®ä¾‹
my_dog = Dog("æ—ºè´¢", "ä¸­åç”°å›­çŠ¬")

# my_dog å°±æ˜¯ä¸€ä¸ªå®ä¾‹ï¼Œå®ƒæ‹¥æœ‰ name å’Œ breed å±æ€§ï¼Œä»¥åŠ bark æ–¹æ³•
print(my_dog.name)  # è¾“å‡º: æ—ºè´¢
print(my_dog.breed) # è¾“å‡º: ä¸­åç”°å›­çŠ¬
my_dog.bark()       # è¾“å‡º: æ—ºè´¢ æ±ªæ±ªå«ï¼
```

| Layer                                             | Output shape        | å‚æ•°é¡¹è¯´æ˜                           | å‚æ•°é‡ (ä¸ª) |
| ------------------------------------------------- | ------------------- | ------------------------------------ | ----------- |
| è¾“å…¥                                              | `[N, M, 64]`        | â€”                                    | â€”           |
| Pointwise Conv1D (1Ã—1)                            | `[N, M, 64]`        | æƒé‡ `1Ã—64Ã—64`, bias `64`            | 4,160       |
| Shared MLP (64â†’16â†’64)                             | `[N,1,64]` (logits) | æƒé‡ `64Ã—16 + 16Ã—64`, biases `16+64` | 2,128       |
| LayerNorm (channel)                               | `[N,1,64]`          | Î³,Î² per channel                      | 128         |
| **é€šé“æ³¨æ„åŠ›å°è®¡**                                |                     |                                      | **6,416**   |
| Expand dim -> `[N,M,64,1]`                        |                     |                                      |             |
| Depthwise convs (5Ã—5,1Ã—7,7Ã—1,1Ã—11,11Ã—1,1Ã—21,21Ã—1) | `[N,M,64,1]`        | depthwise kernels æ€»è®¡ï¼ˆä¸ F æ— å…³ï¼‰  | 103         |
| Spatial 1Ã—1 Conv2D (proj to 1 ch)                 | `[N,M,64,1]`        | weight 1, bias 1                     | 2           |
| LayerNorm (spatial)                               | `[N,M,64,1]`        | Î³,Î² (c=1)                            | 2           |
| Output Conv1D (1Ã—1)                               | `[N,M,64]`          | æƒé‡ `1Ã—64Ã—64`, bias `64`            | 4,160       |
| **ç©ºé—´æ³¨æ„åŠ›å°è®¡**                                |                     |                                      | **4,267**   |
| **æ¨¡å—æ€»è®¡**                                      | `[N,M,64]`          |                                      | **10,683**  |

### 8.BrainNet Viewer

-21.5	66.9	12.1	1	1	Fp1
24.3	66.3	12.5	1	1	Fp2
-39.7	25.3	44.7	2	1	F3
41.9	27.5	43.9	2	1	F4
-49.1	-20.7	53.2	3	1	C3
50.3	-18.8	53.0	3	1	C4
-41.4	-67.8	42.4	5	1	P3
44.2	-65.8	42.7	5	1	P4
-25.8	-93.3	7.7	6	1	O1
25.0	-95.2	6.2	6	1	O2
-52.1	28.6	3.8	2	1	F7
53.2	28.4	-3.1	2	1	F8
-65.8	-17.8	-2.9	4	1	T7
67.4	-18.5	-3.4	4	1	T8
-55.9	-64.8	0.0	4	1	P7
56.4	-64.4	0.1	4	1	P8
0.0	26.8	60.6	2	1	Fz
0.8	-21.9	77.4	3	1	Cz
0.7	-69.3	56.9	5	1	Pz
-62.8	-46.6	-14.66	4	1	TP9
62.8	-46.58	-14.6	4	1	TP10  

è¿™æ˜¯nodeæ–‡ä»¶ edgeæ–‡ä»¶å¯¹è§’çº¿æ˜¯1 é•¿å®½ä¸ºç”µæé€šé“æ•°

### 9.Diffusionæ¨¡å‹å­¦ä¹ ç¬”è®°

![image-20251126151607551](assets/å­¦æœ¯ç¬”è®°/image-20251126151607551.png)

$q(x_t|x_{t-1})$ è¿™ä¸ªè¡¨æ˜ä»–æ˜¯åœ¨å‰ä¸€é¡¹çš„åŸºç¡€ä¸ŠåŠ å™ªå£°æ‰€ä»¥æ˜¯æ¡ä»¶æ¦‚ç‡ï¼ˆé©¬å°”å¯å¤«æ€§æˆ‘ä»¬åªéœ€è¦çŸ¥é“å®ƒç´§é‚»çš„ä¸Šä¸€æ­¥ $x_{t-1}$ å°±è¶³å¤Ÿäº†ã€‚**æˆ‘ä»¬ä¸éœ€è¦çŸ¥é“ $x_0, x_1, \dots, x_{t-2}$ æ˜¯ä»€ä¹ˆæ ·å­çš„**ï¼‰ï¼Œé€‰æ‹©é«˜æ–¯å™ªå£°åŸå› æ˜¯ä¸¤ä¸ªç‹¬ç«‹é«˜æ–¯åˆ†å¸ƒéšæœºå˜é‡ç›¸åŠ ï¼Œç»“æœä»ç„¶æœä»é«˜æ–¯åˆ†å¸ƒï¼Œ

<img src="assets/å­¦æœ¯ç¬”è®°/image-20251127192513401.png" alt="image-20251127192513401" style="zoom: 67%;" />$z \sim \mathcal{N}(\mu, \sigma^2)$ä»£è¡¨å®šä¹‰äº†ä¸€ä¸ªéšæœºå˜é‡zï¼Œå®ƒæœä»ä¸€ä¸ªä¸€èˆ¬æ­£æ€åˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒ)ã€‚è¿™ä¸ªåˆ†å¸ƒå‡å€¼ï¼ˆä¸­å¿ƒä½ç½®æ˜¯$\mu$)ï¼Œæ–¹å·®ï¼ˆç¦»æ•£ç¨‹åº¦æ˜¯$\sigma^2$)ï¼Œ$\frac{z - \mu}{\sigma} \sim \mathcal{N}(0, I)$è¿™æ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–è¿‡ç¨‹ï¼Œå¦‚æœæˆ‘ä»¬æŠŠå˜é‡ $z$ å‡å»å®ƒçš„å‡å€¼ $\mu$ï¼Œå†é™¤ä»¥å®ƒçš„æ ‡å‡†å·® $\sigma$ï¼Œå¾—åˆ°çš„æ–°å˜é‡å°±ä¼šæœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚æ ‡å‡†æ­£æ€åˆ†å¸ƒæ˜¯æœ€ç®€å•çš„é«˜æ–¯åˆ†å¸ƒï¼Œå…¶å‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1ï¼ˆæˆ–è€…åœ¨**å¤šç»´æƒ…å†µä¸‹ä¸ºå•ä½çŸ©é˜µ $I$**)**è¿™ç§å˜æ¢åçš„å˜é‡å¸¸è¢«ç§°ä¸º Z-scoreã€‚**

$z = \mu + \sigma \cdot \epsilon$    å’Œ  $\epsilon \sim \mathcal{N}(0, I)$ è¿™ä¸¤è¡Œæ˜¯é€†æ“ä½œï¼Œä¹Ÿæ˜¯é‡å‚æ•°åŒ–æŠ€å·§æ ¸å¿ƒï¼Œå¼•å…¥æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„è¾…åŠ©å™ªå£°å˜é‡$\epsilon$

ä»»æ„ä¸€ä¸ªå¤æ‚çš„æ­£æ€åˆ†å¸ƒå˜é‡ $z$ï¼Œéƒ½å¯ä»¥çœ‹ä½œæ˜¯ç”±ä¸€ä¸ªç¡®å®šçš„å‡å€¼éƒ¨åˆ† $\mu$ï¼ŒåŠ ä¸Šä¸€ä¸ªè¢«æ ‡å‡†å·® $\sigma$ ç¼©æ”¾è¿‡çš„æ ‡å‡†å™ªå£° $\epsilon$ ç»„åˆè€Œæˆçš„ã€‚

**$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}$** è¿™é‡Œçš„å‡å€¼ $\mu$ æ˜¯ $\sqrt{\alpha_t}x_{t-1}$ï¼Œè¿™é‡Œçš„æ–¹å·® $\sigma^2$ æ˜¯ $1-\alpha_t$ï¼Œæ‰€ä»¥æ ‡å‡†å·® $\sigma$ æ˜¯ $\sqrt{1-\alpha_t}$

### 10.Pytorchå­¦ä¹ ç¬”è®°

#### 1.éªŒè¯å®‰è£…å®Œæˆ

```python
import torch
torch.cuda.is_available()
#æœ‰cudaå°±æ˜¯True,æ²¡æœ‰æ˜¯False
```

#### 2.ä¸¤ä¸ªé‡è¦å‡½æ•°

##### 1)dir()

```python
dir()
dir(torch)
dir(torch.cuda)
#å±•ç¤ºåŒ…çš„å†…å®¹
```

##### 2)help()

```python
help()
#æŸ¥çœ‹ç±»å¦‚ä½•ä½¿ç”¨
```

#### 3.PytorchåŠ è½½æ•°æ®

##### 1ï¼‰Dataset

æä¾›ä¸€ç§æ–¹æ³•è·å–æ•°æ®å’Œå…¶label

ä¼ å…¥ï¼šindex

è¾“å‡ºï¼šData,label

##### 2)å¸¸è§çš„æ•°æ®ç»„ç»‡å½¢å¼

1.å¤šç§åˆ†ç±»æ•°æ®åˆ†åˆ—äºå¤šä¸ªæ–‡ä»¶å¤¹ï¼Œè¿™äº›æ–‡ä»¶å¤¹åå­—ä»£è¡¨æ•°æ®çš„æ ‡ç­¾

2.åŒ…å«è®­ç»ƒæ•°æ®æ–‡ä»¶å¤¹å’Œæ ‡ç­¾æ–‡ä»¶å¤¹ï¼Œä¸è®­ç»ƒæ•°æ®åŒåçš„txtæ–‡ä»¶ä¸­å«æœ‰æ•°æ®çš„label

3.æ•°æ®çš„æ ‡ç­¾ä½“ç°åœ¨æ•°æ®çš„æ–‡ä»¶åä¸Š

##### 3ï¼‰Datasetçš„ä½¿ç”¨

```python
from torch.utils.data import Dataset
```

1.__Dataset__æ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œå› æ­¤æ•°æ®é›†ç±»éœ€è¦ç»§æ‰¿è‡ªè¯¥ç±»

```python
class MyDataset(Dataset)
	def __init__(self):
        pass
```

2.æ‰€æœ‰å­ç±»åº”å½“é‡å†™__getitem__æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯ä¼ å…¥indexè·å–å…¶æ•°æ®å’Œlabel

```python
class MyDataset(Dataset)
	def __getiten__(self,index):
        return data,label
```

3.å­ç±»ä¹Ÿå¯ä»¥é‡å†™__len__æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”¨äºæä¾›æ•°æ®çš„é•¿åº¦

```python
class MyDataset(Dataset)
	def __len__(self):
        return len(self.datadirlist)
```

#### 4.Summery Writerä½¿ç”¨

##### 1)SummeryWriteræ˜¯æ¥è‡ªtensorboardæ¨¡å—çš„å¯è§†åŒ–å·¥å…·

ä½¿ç”¨SummeryWriteræ—¶ï¼Œéœ€è¦ä¸‹è½½tensorboardæ¨¡å—

```powershell
pip install tensorboard -i https://pypi.tuna.tsinghua.edu.cn/simple
```

##### 2)SummeryWriteræ˜¯ä¸€ä¸ªç±»ï¼Œä½¿ç”¨æ—¶å¯ä»¥ä¼ å…¥è¾“å‡ºæ–‡ä»¶å¤¹

```python
writer=SummeryWriter("logs")
#å°†./logsæ–‡ä»¶å¤¹ä½œä¸ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼Œå¦‚æœæ²¡æœ‰è¯¥æ–‡ä»¶å¤¹åˆ™åˆ›å»ºä¸€ä¸ª
```

##### 3)SummeryWriterå†™å…¥å•ä¸ªæ•°æ®

```python
writer.add_scalar(tag:str,scalar_value,global_step:int)
#tagå›¾åï¼Œä¸åŒå›¾åä¼šç”Ÿæˆä¸åŒçš„å›¾
#scalar_valueï¼Œéœ€è¦è¡¨è¾¾çš„yå€¼
#golbal_stepï¼Œéœ€è¦è¡¨è¾¾çš„xå€¼ï¼Œæ³¨æ„æ˜¯æ•´æ•°
```

##### 4ï¼‰SummeryWriterå†™å…¥å›¾ç‰‡

```python
writer.addimage(tag:str,image,global_step:int,dataformats)
#tagå›¾åï¼Œä¸åŒå›¾åä¼šå†™å…¥ä¸åŒçš„å›¾
#imageå›¾åƒæ–‡ä»¶æµ,å¯ä»¥æ˜¯np.ndarray,PIL.Image,tensorä¸‰ç§ç±»å‹
#global_stepæ­¥æ•°ï¼Œå¯ä»¥æ‹–åŠ¨æ­¥æ•°æ¡æ˜¾ç¤ºä¸åŒå›¾ç‰‡
#dataformats,ä¸‰ç§é€šé“çš„é¡ºåºï¼Œtensorå‹ä¸ç”¨æŒ‡å®šï¼Œè€Œndarrayå‹éœ€è¦æŒ‡å®š"WHC"
```

#### 5.Transformsçš„ä½¿ç”¨

##### 1)Transformsæ˜¯æ¥è‡ªpytorchvisionåŒ…çš„å›¾ç‰‡å¤„ç†å·¥å…·

```python
from torchvision import transforms
```

##### 2)ç±»å‹è½¬æ¢å·¥å…·ToTensor

ToTensoræ˜¯ä¸€ä¸ªç±»ï¼Œå…¶ä¸­çš„æ–¹æ³•æ˜¯éé™æ€çš„ï¼Œä½¿ç”¨æ—¶éœ€è¦å®ä¾‹åŒ–

```python
Trans=transforms.ToTensor()
tensorimg=Trans(img)
#imgå¯ä»¥æ”¯æŒä¸¤ç§ç±»å‹ï¼ŒPILè¯»å–çš„Imageç±»å‹å’Œcv2è¯»å–çš„np.ndarrayç±»å‹
```

è¡¥å……ï¼šå½“ç±»ä¸­å«æœ‰é­”æœ¯æ–¹æ³•__call__æ—¶ï¼Œå¦‚æœæŠŠå®ä¾‹å½“æˆå‡½æ•°ä½¿ç”¨ï¼Œåˆ™ä¼šè‡ªåŠ¨è°ƒç”¨é­”æœ¯æ–¹æ³•

##### 3ï¼‰å›¾ç‰‡æ‹‰ä¼¸å·¥å…·Resize

Resizeå®ä¾‹åŒ–æ—¶éœ€è¦ä¼ å…¥æƒ³è¦æ‹‰ä¼¸çš„å¤§å°ï¼Œç±»å‹æ—¶tuple(int,int)

```python
Reshaper=transforms.Resize(size=(300,500))
#æ³¨æ„è¿™é‡Œæ˜¯ä¼ å…¥å…ƒç»„è€Œä¸æ˜¯ä¼ å…¥ä¸¤ä¸ªå‚æ•°
rspimg=Reshaper(tensorimg)
#é­”æœ¯æ–¹æ³•æ”¯æŒçš„tensoræˆ–PILç±»å‹çš„å›¾ç‰‡
#å¦‚æœæ²¡æœ‰é­”æœ¯æ–¹æ³•ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨forwardæ–¹æ³•
rspimg=Reshaper.forward(tensorimg)
```

##### 4)å›¾ç‰‡å½’ä¸€åŒ–å·¥å…·Normalize

Normalizeå®ä¾‹åŒ–æ—¶éœ€è¦ä¼ å…¥å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä¸‰é€šé“å›¾ç‰‡çš„å‡å€¼å’Œæ ‡å‡†å·®æ˜¯é•¿åº¦ä¸º3çš„åˆ—è¡¨

```python
Norm=transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
image_nor=Norm(tensorimg)
#é­”æœ¯æ–¹æ³•éœ€è¦å¡«å…¥çš„å‚æ•°æ—¶tensorç±»å‹çš„å›¾ç‰‡
#å¦‚æœæ²¡æœ‰é­”æœ¯æ–¹æ³•ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨forwardæ–¹æ³•
image_nor=Norm.forward(tensorimg)
```

#### 6.å¤„ç†å’Œä½¿ç”¨torchvisionæ•°æ®é›†

##### 1.ç¤ºä¾‹ï¼šä½¿ç”¨æ•°æ®é›†CIFAR0

```python
import torchvision
train_set=torchvision.datasets.CIFAR10(root="./dataset",train=True,download=True)
test _set=torchvision.datasets.CIFAR10(root="./dataset",train=False,download=True)
#rootæŒ‡å®šæ•°æ®å­˜æ”¾çš„ä½ç½®ï¼ŒTrainæŒ‡å®šè¯¥æ•°æ®é›†æ˜¯å¦æ˜¯è®­ç»ƒæ•°æ®é›†ï¼ŒdownloadæŒ‡å®šæ˜¯å¦ä¸‹è½½æ•°æ®
```

##### 2.ä½¿ç”¨è‡ªå®šä¹‰ä¸‹è½½å·¥å…·ä¸‹è½½torchvisionæ•°æ®é›†

å†™å¥½æ•°æ®é›†åç§°

```python
torchvision.datasets.CIFAR10()
```

ä½¿ç”¨Crtl+é¼ æ ‡å·¦é”®å•å‡»è¿›å…¥æ•°æ®é›†è¯¦æƒ…

```python
url = "https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
```

æ‰¾åˆ°ä¸‹è½½é“¾æ¥ï¼Œç”¨è‡ªå¸¦çš„ä¸‹è½½å·¥å…·è¿›è¡Œä¸‹è½½(è¿…é›·ï¼ŒIDMï¼ŒMotrixç­‰)

æ”¾å…¥rootæŒ‡å®šçš„å¯¹åº”æ–‡ä»¶å¤¹

```python
train_set=torchvision.datasets.CIFAR10(root="./dataset",train=True,download=True)
```

##### 3.å¤„ç†æ•°æ®

ä¸ºæ•°æ®é›†ä¼ å…¥transformså®ä¾‹å³å¯

```python
from torchvision import transforms
import tochvision
Reshape=transforms.Resize((40,40))
train_set=torchvision.datasets.CIFAR10(root="./dataset",train=True,transforms=Reshape,download=True)
```

é€šè¿‡è¯¥å‚æ•°ï¼Œä¸ºæ•°æ®é›†æŒ‡å®šTransforms,å‡½æ•°ä¼šä½¿ç”¨å®ä¾‹å¹¶ä¸”è°ƒç”¨é­”æœ¯æ–¹æ³•è¿›è¡Œè‡ªåŠ¨å¤„ç†

æ³¨ï¼šè¿™ä¹Ÿå¯èƒ½æ˜¯transformsä¸ä½¿ç”¨é™æ€æ–¹æ³•çš„æœ‰ä¸€ç§è€ƒé‡ï¼Œä¸ºäº†æ–¹ä¾¿ä¼ å…¥å®ä¾‹

#### 7.ä½¿ç”¨DataLoaderé…åˆSummaryWriter().add_images

##### 1.å…³äºDataLoader

Dataloaderæ˜¯æ¥è‡ªtorch.data.DataLorderçš„ç±»ï¼Œå…¶æ„é€ å‡½æ•°å«æœ‰å¤šä¸ªå‚æ•°ã€‚

```markdown
		dataset:Datasetç±»å‹ï¼Œéœ€è¦åŠ è½½çš„ç±»
        batch_size:intç±»å‹ï¼Œå¯é€‰å‚æ•°ï¼Œæ¯ä¸ªå›¾ç‰‡é›†çš„å¤§å°
        shuffle:boolç±»å‹ï¼Œè¡¨ç¤ºæ•°æ®æ˜¯å¦æ‰“ä¹±ï¼Œé»˜è®¤ä¸ºFalse
        drop_last:å¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸ºFalse,å¦‚æœä¸èƒ½æ•´é™¤å›¾ç‰‡ç»„æ•°ï¼Œæ˜¯å¦è¦ä¸¢å¼ƒæœ€åçš„æ•°æ®
```

##### 2.ä½¿ç”¨DataLoader

DataLoaderåœ¨å»ºç«‹ä¹‹åï¼Œå¯ä»¥å½“æˆä¸€ä¸ªè¿­ä»£å™¨ä½¿ç”¨ï¼Œæ˜¯å› ä¸ºå…¶çˆ¶ç±»å®šä¹‰äº†ç›¸å…³æ–¹æ³•ã€‚

```python
Dta=DataLoader(Dataset,batch_size=25,shuffle=True,drop_last=True)
writer=SummaryWriter("logs")
idx=0
for i in Dta:
    img,target=i
	writer.add_images("test",img,global_step=idx)
    idx+=1
```

##### 3.æœ€ç»ˆæ•ˆæœ

![image-20240523151330939](assets/å­¦æœ¯ç¬”è®°/image-20240523151330939.png)

#### 8.ç»§æ‰¿å’Œä½¿ç”¨torch.nn.Module

##### 1.å…³äºtorch.nn.Module

torch.nn.Moduleæ˜¯nnç±»çš„åŸºæœ¬éª¨æ¶ï¼Œæ˜¯å®šä¹‰torchç¥ç»ç½‘ç»œç±»éœ€è¦ç»§æ‰¿çš„çˆ¶ç±»ã€‚

torch.nn.Moduleå®ä¾‹åŒ–åä¼šå­˜åœ¨é­”æœ¯æ–¹æ³•__call__ï¼Œè¯¥æ–¹æ³•åœ¨è°ƒç”¨è¯¥å®ä¾‹æ—¶ä¼šå°†å‚æ•°ä¼ ç»™forwardå‡½æ•°ï¼Œå› æ­¤å…¶æ¯ä¸€ä¸ªå­ç±»éƒ½åº”è¯¥é‡å†™forwardå‡½æ•°ã€‚

##### 2.ä½¿ç”¨å’Œæ„å»ºè‡ªå®šä¹‰ç¥ç»ç½‘ç»œ

```python
from torch.nn import Module
class Mynn(Module):
    def __init__(self):
        super().__init__()
        #è°ƒç”¨çˆ¶ç±»çš„æ„é€ å‡½æ•°
    def forward(self,data):
        data+=1
        return data

customnn=Mynn()
print(customnn(10))
#è¾“å‡º11ï¼Œè°ƒç”¨äº†çˆ¶ç±»çš„é­”æ³•å‡½æ•°ï¼Œä½¿ç”¨äº†å­ç±»é‡å†™çš„forwardå‡½æ•°
```



#### 9.äº†è§£å’Œä½¿ç”¨å·ç§¯å’Œå·ç§¯å‡½æ•°torch.nn.functional.conv2d()

##### 1.å·ç§¯çš„æ¦‚å¿µ

<img src="assets/å­¦æœ¯ç¬”è®°/07f1130e29ca49c68e3b445871a3a34b.gif" alt="07f1130e29ca49c68e3b445871a3a34b" style="zoom: 67%;" />

å·ç§¯åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼Œå·ç§¯æ ¸å’Œæ•°æ®ã€‚é€šè¿‡ä½¿ç”¨å·ç§¯å’Œå¯¹æ•°æ®çš„å·ç§¯æ ¸å¤§å°çš„æ•°æ®ä¸æ–­åšç‚¹ä¹˜è®¡ç®—ï¼Œä»è€Œç”Ÿæˆæ–°çš„çŸ©é˜µã€‚

##### 2.ä½¿ç”¨torch.nn.functional.conv2d

convæ—æ˜¯æ¥è‡ªtorch.nn.functionalç±»ä¸‹çš„æ–¹æ³•ï¼ŒåŒ…å«conv1d,conv2då’Œconv3dã€‚

ä½¿ç”¨conv2dæ—¶ï¼Œéœ€è¦æŒ‡å®štwnsorç±»å‹çš„å·ç§¯æ ¸ã€‚

```python
from torch.nn.functional import conv2d
import numpy as np
from torchvision import transforms

#å®šä¹‰æ•°æ®å’Œå·ç§¯æ ¸
#å®šä¹‰è½¬æ¢å™¨
transtools=transforms.ToTensor()
dataset=transtools(np.array([[1,2,9,6,7],[4,3,1,6,9],[7,4,2,6,2],[3,0,9,2,6],[3,5,7,9,0]]))
ker=transtools(np.array([[1,0,1],[0,1,1],[1,2,2]]))
#ToTensoræ–¹æ³•æ¥å—ä¸€ä¸ªnp.arrayå˜é‡ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å°†åˆ—è¡¨å˜é‡è½¬æ¢ä¸ºnp.arrayå˜é‡

dataset=torch.reshape(dataset,(1,1,5,5))
ker=torch.reshape(ker,(1,1,3,3))
#conv2dæ¥å—çš„æ•°æ®æœ‰è¦æ±‚
output=conv2d(input=dataset,weight=ker,stride=1)
'''input: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶åº”ä¸º (N, C_in, H_in, W_in)ï¼Œå…¶ä¸­ N æ˜¯æ‰¹æ¬¡å¤§å°ï¼ŒC_in æ˜¯è¾“å…¥é€šé“æ•°ï¼ŒH_in å’Œ W_in åˆ†åˆ«æ˜¯è¾“å…¥çš„é«˜åº¦å’Œå®½åº¦ã€‚
weight: å·ç§¯æ ¸æƒé‡å¼ é‡ï¼Œå½¢çŠ¶ä¸º (out_channels, in_channels/groups, kernel_height, kernel_width)ã€‚out_channels æ˜¯è¾“å‡ºé€šé“æ•°ï¼Œin_channels/groups è¡¨ç¤ºæ¯ä¸ªç»„çš„è¾“å…¥é€šé“æ•°ã€‚
strideï¼Œå·ç§¯æ­¥é•¿ã€‚'''
```

##### 3.æ‰©å±•ï¼šä½¿ç”¨torch.nn.functional.conv2då¯¹ç°åº¦å›¾ç‰‡è¿›è¡Œå·ç§¯å¤„ç†

```python
import torchvision
import torch
from torchvision import transforms
#è¯»å–CIFæ•°æ®é›†
dataset=torchvision.datasets.CIFAR10(root="./data",train=False,download=True)
#ä½¿ç”¨PILè½¬æ¢ä¸ºç°åº¦å›¾åƒ
img=transforms.ToTensor()(dataset[0][0].convert('L'))
#ä½¿ç”¨reshapeåœ¨ä¸åŠ å…¥ä¿¡æ¯çš„æƒ…å†µä¸‹æ‰©å±•ä¸€ä¸ªç»´åº¦
img=torch.reshape(img,[1]+list(img.shape))
#ä½¿ç”¨å·ç§¯æ ¸
ker=[[0.2,0.3,0.5],[0.2,0.6,0.2],[0.6,0.1,0.3]]
#æ³¨æ„å·ç§¯æ ¸çš„æ•°æ®ç±»å‹éœ€è¦å’Œå›¾ç‰‡tensorçš„æ•°æ®ç±»å‹ä¸€è‡´ï¼Œå°±ç®—doubleä¸int,floatæ•°æ®ç±»å‹å·ç§¯éƒ½ä¼šæŠ¥é”™
ker=torch.FloatTensor(ker)
#å·ç§¯æ ¸ç»´åº¦æ‰©å±•
ker=torch.reshape(ker,[1,1]+list(ker.shape))
#å·ç§¯
output=torch.nn.functional.conv2d(input=img,weight=ker)
#æŸ¥çœ‹å·ç§¯ç»“æœ
imghandled=transforms.ToPILImage()(torch.reshape(output,(1,30,30)))
imghandled.show()
```

#### 10.åˆ©ç”¨Moduleéª¨æ¶æ„å»ºå’Œä½¿ç”¨torch.nn.Conv2dç±»

##### 1.ç»§æ‰¿è‡ªModuleçš„å­ç±»åœ¨ç±»å¯¹è±¡è¢«å½“ä½œå‡½æ•°ä½¿ç”¨æ—¶ä¼šè°ƒç”¨å­ç±»çš„forwardæ–¹æ³•

```python
import torch
class Testclass(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self,i,j,k):
        print(i,j,k)
TC=Testclass()
TC(1,2,3)

#è¾“å‡º1 2 3
```

##### 2.åˆå§‹åŒ–å’Œä½¿ç”¨Conv2dç±»

```python
class Myclass(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self,image):
        self.imgconv2d=torch.nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)
        return self.imgconv2d(image)
    #in_channelsè¡¨ç¤ºè¾“å…¥çš„é€šé“æ•°ï¼Œout_channelsæ˜¯è¾“å‡ºçš„é€šé“æ•°ï¼Œkernel_sizeæ˜¯å·ç§¯æ ¸çš„å¤§å°ï¼Œpaddingæ˜¯ä½¿ç”¨è¾¹ç¼˜å¡«å……ï¼Œstrideæ˜¯å·ç§¯æ­¥é•¿
```

##### 3.ç»“åˆSummaryWriterä½¿ç”¨ç¥ç»ç½‘ç»œç±»

```python
import torch
import torchvision
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
class Myclass(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self,image):
        self.imgconv2d=torch.nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)
        return self.imgconv2d(image)

trans=torchvision.transforms.ToTensor()
Dataset=torchvision.datasets.CIFAR10(root="./data",train=False,download=True,transform=trans)
#ç”±äºSummaryWriteréœ€è¦çš„æ˜¯ndarrayç±»æˆ–è€…tensorç±»ï¼Œéœ€è¦ä½¿ç”¨torchvision.transforms.ToTensorç±»è¿›è¡Œè½¬æ¢
Dta=DataLoader(Dataset,batch_size=64,shuffle=True,drop_last=True)
writer=SummaryWriter("logs")
idx=0
for i in Dta:
    img,target=i
    img=Myclass()(img)
    #åœ¨æ­¤å¤„å®ä¾‹åŒ–ç±»å¹¶ä¸”ä¼ å…¥æ•°æ®
    writer.add_images("test",img,global_step=idx)
    idx+=1
writer.close()
```

#### 11.æ„å»ºå’Œä½¿ç”¨torch.nn.MaxPool2dç±»å¯¹äºŒç»´tensoræ•°æ®è¿›è¡Œæ± åŒ–

##### 1.å…³äºæ± åŒ–

æ± åŒ–å’Œå·ç§¯çš„æ“ä½œæ˜¯ç±»ä¼¼çš„ï¼Œæ± åŒ–æ‹¥æœ‰ä¸€ä¸ªæ± åŒ–æ ¸ï¼Œé€šè¿‡å¯¹æ± åŒ–æ ¸å¯¹é½çš„æ•°æ®å–æœ€å¤§å€¼ï¼Œä»è€Œå®ç°æœ€å¤§æ± åŒ–æ•ˆæœã€‚

##### 2.MaxPool2dç±»

MaxPool3dç±»çš„åˆå§‹åŒ–

```python
#kernel_size:intç±»å‹ï¼Œè¯¥å‚æ•°ç”¨äºæŒ‡å®šæ± åŒ–æ ¸çš„å¤§å°ã€‚
#stride:intæˆ–tupleç±»å‹ï¼Œç”¨äºæŒ‡å®šåœ¨x,yæ–¹å‘æ± åŒ–æ ¸æ­¥è¿›çš„æ­¥é•¿ã€‚æ³¨æ„ï¼Œè¯¥å‚æ•°çš„é»˜è®¤å€¼æ˜¯kernel_size
#dilation:intç±»å‹ï¼ŒæŒ‡å®šæ± åŒ–æ ¸çš„ç©ºè…”å¤§å°ã€‚ä¾‹å¦‚ï¼šå½“dilationä¸º1ä¸”kernel_size=3æ—¶ï¼Œæ± åŒ–æ ¸ä¼šä»5*5çš„æ•°æ®ä¸­å–å‡º9ä¸ªç‚¹çš„æœ€å¤§å€¼è¿›è¡Œå¤„ç†ã€‚
#ceil_mode:boolç±»å‹ï¼Œè¡¨ç¤ºæ˜¯å¦åœ¨æ— æ³•æ­¥è¿›åˆ°kernel_size^2çš„æ•°æ®æ—¶å¿½ç•¥è¿™äº›æ•°æ®ã€‚é»˜è®¤ä¸ºFalse,è¡¨ç¤ºä¸ä¼šå¿½ç•¥ã€‚
```

åˆå§‹åŒ–ç±»

```python
mypool=torch.nn.MaxPool2d(kernel_size=3)
```

##### 3.MaxPool2dç±»å¯¹è±¡callæ–¹æ³•åªæœ‰ä¸€ä¸ªå¿…è¦å‚æ•°

```python
img=mypool()(img)
#è¦æ±‚imgæ—¶tensorå¯¹è±¡ï¼Œç»´åº¦ä¸º4ï¼Œå› æ­¤è¦å¯¹3é€šé“RGBå›¾åƒ(3)åšToTensorå’Œreshapeå˜æ¢
```

#### 12.éçº¿æ€§æ¿€æ´»ç±»torch.nn.*

##### 1.éçº¿æ€§æ¿€æ´»ç±»

éçº¿æ€§æ¿€æ´»ç±»æœ‰å¾ˆå¤šç§ï¼Œæ ¹æ®ä¸åŒçš„è®ºæ–‡ç ”å‘ã€‚

ä¾‹å¦‚ï¼š

```python
torch.nn.ReLU()
torch.nn.Sigmoid()
```

è¿™äº›ç±»åœ¨åˆå§‹åŒ–æ—¶ä¸éœ€è¦æŒ‡å®šå‚æ•°ï¼Œåœ¨ä½¿ç”¨æ—¶ä¼šå¯¹tensoræ•°æ®ç±»å‹çš„æ¯ä¸€ä¸ªæ•°æ®åº”ç”¨å˜æ¢ã€‚

##### 2.ä½¿ç”¨æ–¹æ³•

```python
from torch import ReLU
class Linearclass(torch.nn.Module):
	def __init__(self):
        super().__init__()
        
    def datalinear(self,data):
        Re=ReLU()
        return Re(data)
```

è¯¥å±‚çš„å®è´¨æ˜¯å¯¹æ•°æ®åº”ç”¨ä¸€ä¸ªå‡½æ•°ã€‚

#### 13.çŸ©é˜µå±•å¼€flattenå’Œçº¿æ€§å˜æ¢ç±»Linear

##### 1.çŸ©é˜µå±•å¼€æ–¹æ³•flatten

flattenæ˜¯èƒ½å¤Ÿå°†é«˜ç»´çŸ©é˜µæŒ‰é¡ºåºå±•å¼€æˆä¸€ç»´åˆ—è¡¨çš„æ–¹æ³•ï¼Œå…¶æ¥æºæ˜¯torchï¼Œå¿…è¦å‚æ•°åªæœ‰ä¸€ä¸ªï¼Œå¿…é¡»æ˜¯æ˜¯tensorç±»å‹çš„çŸ©é˜µã€‚

```python
import torch
data=torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])
output=torch.flatten(data)
print(output)
#tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])
```

##### 2.å®ç°ç±»ä¼¼åŠŸèƒ½çš„reshapeæ–¹æ³•

reshapeæ–¹æ³•ä¹Ÿæ˜¯torchä¸‹çš„çŸ©é˜µå˜åŒ–æ–¹æ³•ï¼Œå½“æŸç»´åº¦çš„å€¼ä¸ºé˜¶æ•°å†™-1æ—¶ï¼Œä¼šè‡ªåŠ¨æ¨å¯¼è¯¥ç»´åº¦çš„é˜¶æ•°ã€‚

```python
import torch
data=torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])
output=torch.reshape(data,(1,1,-1))
print(output)
#tensor([[[1., 2., 3., 4., 5., 6., 7., 8., 9.]]])
```

å¾ˆæ˜æ˜¾ï¼Œreshapeæ–¹æ³•ä¸ä¼šæ”¹å˜æ•°æ®çš„ç»´æ•°ã€‚

##### 3.çº¿æ€§å˜æ¢ç±»Linear

Linearç±»æ˜¯ä¸€ä¸ªå’Œå·ç§¯ç±»æ± åŒ–ç±»ç±»ä¼¼çš„ï¼Œåˆå§‹åŒ–çš„å¿…é¡»å‚æ•°åªæœ‰æ•°æ®å¤§å°å’Œéœ€æ±‚å˜æ¢å¤§å°çš„ç±»ã€‚

```python
import torch
from torch import Linear
class Linearclass(torch.nn.Module):
	def __init__(self):
        super().__init__()
        
    def datalinear(self,data):
        Lin=Linear(64,10)
        return Lin(data)
```

é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œ64é•¿åº¦çš„tensoræ•°æ®å˜ä¸ºäº†10é•¿åº¦çš„ã€‚

#### 14.ä½¿ç”¨Sequentialç±»æ„å»ºç¥ç»ç½‘ç»œ

##### 1.Sequentialç±»æ˜¯ä¸€ä¸ªå¯ä»¥ä¸²è”ç±»å¯¹è±¡çš„torch.nnç±»

Sequentialçš„å‚æ•°æ˜¯ç±»çš„å¯¹è±¡ï¼Œè¦æ±‚è¯¥å¯¹è±¡ç»§æ‰¿torch.nn.Moduleéª¨æ¶ï¼Œè€Œä¸”å®Œæˆäº†forwardå‡½æ•°çš„é‡å†™ã€‚

##### 2.Sequentialç±»çš„ä½¿ç”¨

ä¾‹å¦‚è¿™å¼ å›¾ï¼š

![ç‚¹å‡»æŸ¥çœ‹å›¾ç‰‡æ¥æº](assets/å­¦æœ¯ç¬”è®°/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAcXFfOTMyMDE2NTYx,size_20,color_FFFFFF,t_70,g_se,x_16)

ä½¿ç”¨Sequentialå¤„ç†æ„å»ºå±‚

```python
        self.prenet=Sequential(
            Conv2d(in_channels=3,out_channels=32,kernel_size=(5,5),padding=2),
            MaxPool2d(kernel_size=2),
            Conv2d(in_channels=32,out_channels=32,kernel_size=(5,5),padding=2),
            MaxPool2d(kernel_size=2),
            Conv2d(in_channels=32,out_channels=64,kernel_size=(5,5),padding=2),
            MaxPool2d(kernel_size=2),
            Flatten(),
            Linear(1024,64),
            Linear(64,10)
        )
```

ç›¸å½“äºå°†æ‰€æœ‰å±‚æ•´åˆåˆ°äº†Sequentialç±»ä¸­ã€‚

##### 3.SummaryWriterç±»ç»“åˆç¥ç»ç½‘ç»œSequentialç±»çš„ä½¿ç”¨

SummaryWriterç±»èƒ½å¤Ÿå’ŒSequentialç±»ç»“åˆä½¿ç”¨ï¼Œåœ¨tensorboardä¸­æ‰“å°å‡ºæ¨¡å‹çš„å…·ä½“å±‚æ•°å’Œæµç¨‹ã€‚

```python
writer=SummaryWriter("logs")
writer.add_graph(netModule,input)
```

æ•ˆæœå¦‚ä¸‹å›¾

![image-20240525235447841](assets/å­¦æœ¯ç¬”è®°/image-20240525235447841.png)

##### 4.Sequentialç±»è°ƒè¯•å°æŠ€å·§

ç¼–å†™ç±»ptnï¼Œèƒ½å¤Ÿæ‰“å°Sequentialè®¡ç®—è¿‡ç¨‹ä¸­çš„æ•°æ®å°ºå¯¸ï¼Œä»è€Œå®ç°è°ƒè¯•ã€‚

```python
class prn(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self,data):
        print(data.shape)
        return data
```

#### 15 æŸå¤±å‡½æ•°çš„ä½¿ç”¨

##### 1.æ³¨æ„æŸå¤±å‡½æ•°çš„è¾“å…¥è¾“å‡ºæ•°æ®ç±»å‹

ä¸åŒçš„æŸå¤±å‡½æ•°æœ‰ç€ä¸åŒçš„è¾“å…¥è¾“å‡ºæ•°æ®ç±»å‹ã€‚

CrossEntropyLossç±»

```python
#CrossEntropyLossç±»æ˜¯ä¸€ä¸ªæŸå¤±å‡½æ•°ç±»ï¼Œå…¶åˆå§‹åŒ–æ—¶æ²¡æœ‰å¿…è¦å‚æ•°ï¼Œä½†æ˜¯å…¶ä½¿ç”¨æ—¶éœ€è¦ä¼ å…¥å„ä¸ªåˆ†ç±»çš„è®¡ç®—æ¦‚ç‡å’Œæ ‡ç­¾ã€‚
#è¯¥ç±»æ˜¯ä¸€ä¸ªä¸“ç”¨äºè¡¡é‡åˆ†ç±»æ•ˆæœçš„ç±»
CELoss=CrossEntryLoss()
PerLoss=CELoss(Modle(img),target)
#è¯¥ç±»çš„è®¡ç®—åŸç†åœ¨æ–‡æ¡£ä¸­æŒ‡å®šäº†ï¼Œèƒ½å¤Ÿä½¿å¾—å½“æ ‡ç­¾çš„æ¦‚ç‡è¶Šé«˜ï¼Œéæ ‡ç­¾çš„æ¦‚ç‡è¶Šä½æ—¶ï¼ŒæŸå¤±å‡½æ•°çš„å¤§å°è¶Šå°
```

L1Lossç±»

```python
#CrossEntropyLossç±»æ˜¯ä¸€ä¸ªæŸå¤±å‡½æ•°ç±»ï¼Œå…¶åˆå§‹åŒ–æ—¶æ²¡æœ‰å¿…è¦å‚æ•°ï¼Œä½¿ç”¨æ—¶éœ€è¦ä¼ å…¥ç»“æœtensorç±»å’Œæ ‡ç­¾tensorç±»
#è¯¥ç±»ä¼šè®¡ç®—ç»“æœå’Œæ ‡ç­¾çš„ç»å¯¹å€¼å·®å’Œ
#å…¶åˆå§‹åŒ–æ—¶æœ‰ä¸€ä¸ªå¯é€‰å‚æ•°reduction,é»˜è®¤ä¸º"mean",è¡¨ç¤ºæ±‚å‡ºç»å¯¹å€¼å·®å’Œåä¼šå¯¹æ ·æœ¬å¤§å°æ±‚å¹³å‡
#å½“reductionå–"sum"æ—¶ï¼Œåªæ±‚å’Œ
LossFunc=L1Loss()
PerLoss=LossFunc(torch.Tensor([1,2,3]),torch.Tensor([2,1.1,3.3]))
#å¦‚æœä¸ºreduction="sum":PerLoss=2.2
#å¦‚æœä¸ºreduction="mean":PerLoss=0.73
```

MSELossç±»

```python
#CrossEntropyLossç±»æ˜¯ä¸€ä¸ªæŸå¤±å‡½æ•°ç±»ï¼Œå…¶åˆå§‹åŒ–æ—¶æ²¡æœ‰å¿…è¦å‚æ•°ï¼Œä½¿ç”¨æ—¶éœ€è¦ä¼ å…¥ç»“æœtensorç±»å’Œæ ‡ç­¾tensorç±»
#è¯¥ç±»ä¼šè®¡ç®—ç»“æœå’Œæ ‡ç­¾çš„ç»å¯¹å€¼å·®å¹³æ–¹å’Œ
LossFunc=MSELoss()
PerLoss=LossFunc(torch.Tensor([1,2,3]),torch.Tensor([2,1.1,3.3]))
#PerLoss=0.63
```

##### 2.åå‘ä¼ æ’­å’Œè‡ªåŠ¨æ±‚å¯¼æœºåˆ¶

æŸå¤±å‡½æ•°ç±»çš„backwardæ–¹æ³•èƒ½å¤Ÿå¯¹æ¯å±‚ç¥ç»ç½‘ç»œæ±‚å–æ¢¯åº¦ï¼Œä»è€Œä¸ºä¼˜åŒ–å™¨æ›´æ–°æä¾›ä¾æ®ã€‚

```python
LossFunc.backward()
```

ä½¿ç”¨è¯¥æ–¹æ³•åï¼Œtorchä¼šå¯¹æ¯å±‚ç½‘ç»œè‡ªåŠ¨æ±‚æ¢¯åº¦ï¼Œå¹¶ä¸”å°†æ¢¯åº¦ç´¯åŠ åˆ°Sequentialç±»çš„Moduleå®ä¾‹ä¸­å„å±‚çš„æƒé‡å’Œåç½®ç±»çš„gradå±æ€§ä¸‹ï¼Œä»è€Œä½¿å¾—ä¼˜åŒ–å™¨èƒ½å¤Ÿé€šè¿‡step()æ–¹æ³•å–å¾—è¿™äº›å±æ€§ã€‚

#### 16.optmizerçš„å®šä¹‰å’Œä½¿ç”¨

##### 1.torchæä¾›çš„éƒ¨åˆ†optimizer

```python
#SGD (Stochastic Gradient Descent): æœ€åŸºç¡€çš„éšæœºæ¢¯åº¦ä¸‹é™æ³•ã€‚
torch.optim.SGD()
#Adam (Adaptive Moment Estimation): ç»“åˆäº†åŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ ç‡çš„æ–¹æ³•ï¼Œæ˜¯ç›®å‰éå¸¸æµè¡Œçš„ä¼˜åŒ–å™¨ã€‚
torch.optim.Adam()
#RMSprop (Root Mean Square Propagation): ä½¿ç”¨å¹³æ–¹æ¢¯åº¦çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡æ¥è°ƒæ•´å­¦ä¹ ç‡ã€‚
torch.optim.RMSprop()
```

##### 2.optimizeréœ€è¦ç”¨torch.nn.Module.parameters()å’Œå­¦ä¹ ç‡lræ¥åˆå§‹åŒ–

```python
optim=Adam(MyNet.parameters(),lr=0.01)
#lræŒ‡çš„æ˜¯å­¦ä¹ ç‡,learning rate
```

##### 3.optimizerçš„ä½¿ç”¨å’Œè¿ä½œè¿‡ç¨‹

optimizeré…åˆæŸå¤±å‡½æ•°ä½¿ç”¨ï¼ŒæŸå¤±å‡½æ•°LossFuncå°†è‡ªåŠ¨æ±‚å¯¼ç»“æœåœ¨Backward()è°ƒç”¨æ—¶å†™å…¥æ¯ä¸€å±‚æ¨¡å‹çš„æƒé‡å’Œåç½®ç±»çš„gradå‚æ•°ä¸‹ï¼Œå½“optimizerçš„step()æ–¹æ³•è°ƒç”¨æ—¶ï¼Œä¼šè·å–è¿™äº›gradæ¢¯åº¦ä»¥æ­¤ä¸ºä¾æ®å¯¹æƒé‡è°ƒæ•´ã€‚

ç”±äºLossFunc.backward()æ–¹æ³•æ˜¯å°†æ¢¯åº¦ç´¯åŠ åˆ°ç½‘ç»œä¸­ï¼Œè¦å°†è¿™äº›æ¢¯åº¦åœ¨æ¯æ¬¡æ¸…é›¶ã€‚

#### 17.ä½¿ç”¨å’Œä¿®æ”¹torchvisionæä¾›çš„æ¨¡å‹

##### 1.torchvisonçš„æ¨¡å‹ä½äºtorchvision.modelsä¸­

æ¯”å¦‚ä½¿ç”¨torchvisionæä¾›çš„è§†è§‰åˆ†ç±»æ¨¡å‹vgg19ï¼š

```python
import torchvision
vgg19=trochvision.models.vgg19(weight="IMAGENET1K_V1",progress=True)
#è¿™ä¸¤ä¸ªå‚æ•°æ˜¯å®˜æ–¹æ–‡æ¡£ç»™å®šçš„ï¼Œweightè¡¨ç¤ºä¸‹è½½çš„æ•°æ®æ˜¯å¦ä½¿ç”¨ä¸è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œprogressè¡¨ç¤ºæ˜¯å¦æ˜¾ç¤ºä¸‹è½½è¿›åº¦
```

##### 2.ä¸ºæ¨¡å‹åŠ å…¥å±‚

è¿™æ˜¯è¡¨ç¤ºVGGæ¨¡å‹çš„ç½‘ç»œç»“æ„ã€‚

```python
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (26): ReLU(inplace=True)
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): ReLU(inplace=True)
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
```

å‘vggåŠ å…¥ä¸€ä¸ªçº¿å½¢å±‚ï¼Œåå­—ä¸ºlinear

```python
vgg19.add_module(name="linear",Linear(in_features=1000,out_features=10))
```

å‘vgg.classifieråŠ å…¥ä¸€ä¸ªçº¿æ€§å±‚ï¼Œåå­—ä¸º7

```python
vgg19.classifier.add_module(name="7",Linear(in_features=1000ï¼Œout_features=10))
```

##### 3.æ›¿æ¢æ¨¡å‹å±‚

è™½ç„¶å‘æ¨¡å‹åŠ å…¥å±‚å¾ˆæ–¹ä¾¿ï¼Œä½†æ˜¯æœ‰æ—¶å€™æ–°åŠ å…¥çš„å±‚ä¸ä¸€å®šè¢«æ¨¡å‹ä¼ æ’­ï¼ŒåŠ å…¥çš„å±‚å°±å˜ä¸ºæ²¡ç”¨çš„å±‚äº†ã€‚

è¿™æ—¶æˆ‘ä»¬éœ€è¦æ›¿æ¢æ¨¡å‹ä¸­æœ‰ç”¨çš„å±‚ã€‚

æ¯”å¦‚ä»¥å›¾åƒè¯†åˆ«ç½‘ç»œResNet50ï¼Œå…¶æœ€åçš„ç»“æ„æ˜¯è¿™æ ·çš„ï¼š

```python
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
```

å½“æˆ‘ä»¬å‘modle.resnetå…¶ä¸­åŠ å…¥çº¿å½¢å±‚Refcï¼Œæ¨¡å‹æ˜¯è¿™æ ·çš„ï¼š

```python
(avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
(fc): Linear(in_features=2048, out_features=1000, bias=True)
(refc): Linear(in_features=1000, out_features=100, bias=True)
```

ä½†æ˜¯è¾“å‡ºçš„æ—¶å€™outputsä»ç„¶æ˜¯size(1,1000),è¯´æ˜æ¨¡å‹æ²¡æœ‰ç»è¿‡è¯¥å±‚ã€‚

é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ï¼š

```python
model.fc=Sequential(Linear(in_features=2048,out_features=1000,bias=True),
					Lineat(in_features=1000,out_features=100,bias=True))
```

#### 16.å®Œæ•´çš„æ¨¡å‹è®­ç»ƒå¥—è·¯

##### 1.æ„å»ºDataset

Datasetå¯ä»¥ä½¿ç”¨torchvisionæä¾›çš„æ•°æ®é›†

```python
Dataset=torchvision.dataset.CIFAR10(root="./data",download=True,transfer=torchvison.transforms.ToTensor())
```

ä¹Ÿå¯ä»¥è‡ªå·±å†™Datasetæ•°æ®é›†ï¼Œä½¿ç”¨æ•£è£…çš„å›¾ç‰‡æ–‡ä»¶ç­‰ï¼Œé‚£ä¹ˆè¦é‡å†™__getitem__ç±»å’Œå¯é€‰æ‹©é‡å†™__len__ç±»

```python
datadir = "./data/train_data_all"

class saku_dataset(Dataset):
    def __init__(self, path, mode="train"):
        super().__init__()
        self.Dire = open("./data/targetsdir/targets.txt", "r")
        self.Dire = json.load(self.Dire)
        self.filedir = path
        self.path = datadir + "/" + path + "/" + mode

    def __getitem__(self, idx):
        img = Image.open(self.path + "/" + os.listdir(self.path)[idx])
        if img.mode == "RGBA":
            img = img.convert("RGB")
        img = torchvision.transforms.ToTensor()(img)
        target = int(self.Dire[self.filedir])
        return img, target

    def __len__(self):
        return len(os.listdir(self.path))
```

##### 2.æ„å»ºDataLoader

dataloaderæ˜¯ä¸€ä¸ªæ•°æ®è¿­ä»£å™¨ç±»ï¼Œè¦æ±‚ç”¨ä¸€ä¸ªDatasetå¯¹è±¡æ¥åˆå§‹åŒ–ï¼Œæœ‰è®¸å¤šå¯é€‰å‚æ•°ã€‚

```python
datasets_test = DataLoader(dataset=test_data, batch_size=1, shuffle=True, drop_last=True)
```

##### 3.å®šä¹‰æ¨¡å‹ç±»

æ¨¡å‹ç±»å¿…é¡»æ˜¯ç»§æ‰¿è‡ªnn.Moduleçš„ç±»ï¼Œä¸ºäº†ä¿è¯å…¶åŠŸèƒ½ï¼Œè¦å°†å±‚æ·»åŠ åˆ°æ­£å‘ä¼ æ’­æ–¹æ³•__forward__ä¸­ã€‚

```python
class MyModel(nn.Module):
	def __init__(self):
        super().__init__()
        self.mod=Sequential(
          	...
        )
    def forward(self,img):
        return	self.mod(img)
```

##### 4.å®šä¹‰æŸå¤±å‡½æ•°

æŸå¤±å‡½æ•°ä½¿ç”¨pytorchæä¾›çš„æŸå¤±å‡½æ•°å³å¯ã€‚

```python
LossFunc=torch.nn.CrossEntropyLoss()
```

åœ¨pytorchå®˜æ–¹æ–‡æ¡£é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°ã€‚

##### 5.å®šä¹‰ä¼˜åŒ–å™¨

åœ¨pytorchå®˜æ–¹æ–‡æ¡£ä¸­æ‰¾åˆ°åˆé€‚çš„ä¼˜åŒ–å™¨ï¼Œæ¯”å¦‚äºšå½“Adamå’Œæ¢¯åº¦ä¸‹é™SGDç­‰ã€‚

```python
optim=torch.optm.Adam(model_rewriter.parameters())
```

äºšå½“çš„å¿…è¦å‚æ•°åªæœ‰æ¨¡å‹ç±»å¯¹è±¡çš„parameterså‚æ•°è¿­ä»£å™¨ã€‚å­¦ä¹ ç‡ä¼šè‡ªé€‚åº”ä½¿ç”¨ã€‚

##### 6.æ„å»ºè®­ç»ƒå’Œæµ‹è¯•æµç¨‹

æˆ‘ä»¬ä»è®­ç»ƒå’Œæµ‹è¯•çš„è¿­ä»£å™¨ä¸­æå–æ•°æ®å’Œæ ‡ç­¾ï¼Œç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®ã€‚

è®­ç»ƒæ•°æ®ï¼š

```python
for data in dataset_train:
	img,target=data
    #å–å‡ºæ•°æ®
    output=model(img)
    #æ¨¡å‹å¤„ç†æ•°æ®
    optim.zero_grad()
    #æ¸…ç©ºæ¢¯åº¦
    PerLoss=LossFunc(output,target)
    #è®¡ç®—æŸå¤±
    PerLoss.backward()
    #åå‘ä¼ æ’­å åŠ æ¢¯åº¦
    optim.step()
    #æ­¥è¿›ä¼˜åŒ–å™¨
```

æµ‹è¯•æ•°æ®ï¼š

```python
Full_Loss=0
for data in dataset_test:
	with torch.no_grad():
		img,target=data
    	#å–å‡ºæ•°æ®
    	output=model(img)
    	#æ¨¡å‹å¤„ç†æ•°æ®
    	PerLoss=LossFunc(output,target)
    	#è®¡ç®—æŸå¤±
		Full_Loss+=PerLoss
```

è¿™æ˜¯ä¸€ä¸ªè®­ç»ƒè½®æ¬¡çš„ä»£ç ï¼Œæˆ‘ä»¬éœ€è¦è®­ç»ƒæ›´å¤šè½®æ¬¡ä»è€Œæ‰¾åˆ°æ¨¡å‹çš„æœ€å¥½è¡¨ç°ä½ç½®ã€‚

åœ¨æµ‹è¯•æ•°æ®æ—¶å¯ä»¥ä½¿ç”¨SummeryWriterçš„add_scalaræ–¹æ³•ç»˜åˆ¶è®­ç»ƒæŸå¤±å›¾ï¼Œä»è€Œè¾¾åˆ°æœ€å¥½æ•ˆæœã€‚

```python
writer.add_scalar("testloss",scalar_value=Full_Loss,global_step=epoch)
```

å°†è½®æ•°å†™å…¥æ­¥æ•°ä¸­ï¼Œä»è€Œèƒ½å¤Ÿå¾ˆå¥½å±•ç¤ºéšç€è®­ç»ƒè¿›ç¨‹æŸå¤±çš„å˜åŒ–ã€‚
